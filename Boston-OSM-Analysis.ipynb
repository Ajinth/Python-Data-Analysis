{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "I have been living in the Boston area for the last few years since grad school. The dataset analyzed for the purposes of this project pertains to the Boston area. The Boston area dataset was exported from [openstreetmaps](http://www.openstreetmap.org/#map=17/40.71652/-73.94470&layers=H). The analysis included the following steps \n",
    "\n",
    "* **Question Phase:** This phase involves asking general questions about the dataset. The questions involve the problem we are trying to solve for. \n",
    "* **Data Auditing:** This phase involves auditing the data to identify anomalies and patterns. E.g. In the streetmap data we could run into street names which have some kind special characters in them, or we could run into zipcodes in the Boston area that have some kind of alphabetical characters in them. \n",
    "* **Data Cleansing:** This phase involves classifying the anomalies that are identified in the previous step and devising approaches to clean up the data. The cleansing could be either manual or done programmatically. The project assumes a programmatic way to cleansing some of the anomalies. \n",
    "\n",
    "Data Auditing and Data Cleansing follow a repetive approach till a fair amount of data anomalies have been identified and also cleansed approrpriately. \n",
    "\n",
    "* **Conclusion:** This phase involves drawing conclusion about the dataset, based on the auditing and cleansing steps \n",
    "* **Communication:** The phase involves communicating the results of the analysis to the audiences. In a real life scenario this would be the business users who make business decisions based on the dataset analysis. \n",
    "\n",
    "In addition, this project also involves importing the dataset into [mongoDB](https://www.mongodb.com/), followed by executing some of the mongoDB's aggregation commands to further analyze the dataset that has been imported. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Phase\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Auditing\n",
    "## Identifying the TAGS along with the count of occurences of each of the TAGS\n",
    "\n",
    "This step involves doing an initial analysis of the dataset and doing an assessment of the XML nodes. The step also involves counting the number of instances of the specific node. While this step does provide a good start to the data auditing process, it does not answer a whole of questions that needs to be answered. This step definitely helps us confirm the validity of the XML format as the XML parser (ET.iterparse) is able to parse through the entire XML file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {'node': 444899, 'nd': 551066, 'bounds': 1, 'member': 5284, 'tag': 221456, 'relation': 645, 'way': 75362, 'osm': 1})\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "filename = 'boston.osm'\n",
    "\n",
    "def test(): \n",
    "    tag_list = []\n",
    "    tag_dict = defaultdict(int)\n",
    "    for _, element in ET.iterparse(filename): \n",
    "        tag_list.append(element.tag)\n",
    "    for item in tag_list: \n",
    "        tag_dict[item] += 1\n",
    "    pprint.pprint(tag_dict)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Auditing (contd)\n",
    "## Identifying the Count of Unique Users (based on UIDs) \n",
    "OpenSteet map being an openly available map which can be updated by users all over the world, it made sense to get an idea of the number of unique users who have contributed to the map. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Unique Users: 848\n",
      "set(['701372', '3057995', '378464', '14850', '967832', '152074', '4581744', '2176051', '113450', '45027', '1084189', '1723055', '2219985', '70696', '1836471', '1723831', '616774', '2406578', '843366', '396743', '60604', '256900', '4801391', '985060', '252811', '2859541', '1956174', '487535', '110489', '966176', '1802093', '1964257', '3753426', '3401472', '151559', '352232', '2080154', '2411240', '1815503', '2825553', '94578', '1679807', '4667099', '3355238', '2663591', '3846187', '233028', '3711221', '15750', '4732', '1896093', '1691206', '1884900', '2318', '83629', '29320', '4459317', '5013298', '3461700', '2859289', '621028', '674872', '47892', '8609', '38487', '2320085', '52411', '372391', '198831', '3245344', '118021', '5014050', '668245', '297464', '1963816', '336460', '5089369', '701297', '602100', '42429', '1870581', '2031562', '398754', '2851892', '2500516', '3571425', '510166', '4937878', '563947', '69777', '128470', '690266', '3582', '927001', '58277', '2441744', '1783785', '3563758', '2856869', '81909', '3198900', '1002879', '1002877', '4582473', '7906', '492311', '2353539', '2017504', '2252683', '2441830', '1294353', '41904', '111652', '246', '210579', '326503', '79591', '4951', '4809863', '2190045', '618377', '2176257', '401297', '90000', '131160', '133347', '2267677', '290744', '301894', '2456153', '384894', '410823', '4952389', '1825528', '352459', '609760', '3343919', '757042', '1472711', '580678', '473471', '172061', '627713', '4554452', '871001', '932658', '8909', '2867344', '24452', '28145', '104962', '479256', '2044639', '436419', '3828875', '4424608', '130680', '244562', '626367', '86253', '2847988', '3396423', '500006', '1431032', '55782', '172941', '510836', '3876243', '689576', '1860061', '3962', '1832883', '574454', '286581', '4633019', '1482725', '120468', '3392638', '159621', '28559', '2644101', '25398', '3966467', '715371', '505131', '456511', '339172', '3431871', '950045', '99637', '185721', '1762154', '624003', '3759677', '100054', '2906398', '490580', '3040608', '4963142', '1424907', '3695876', '23500', '132538', '2879927', '498743', '123633', '2905914', '372341', '162924', '716675', '1744893', '3573011', '39457', '2631694', '267808', '1288', '1498035', '8764', '48060', '40242', '367870', '3573157', '1443767', '878284', '307202', '1306', '1024769', '194284', '527535', '1137842', '131059', '206961', '3518484', '4652571', '1589336', '163396', '5359', '107257', '4643671', '3406980', '327264', '1869000', '1847014', '46220', '146680', '2942213', '3695506', '2822392', '130472', '3639088', '1203395', '2256045', '2015224', '61257', '4245387', '706371', '241195', '1355899', '103574', '2550164', '1867872', '9903', '2061617', '289116', '1956483', '91847', '2997513', '173918', '134535', '3609361', '153669', '2912460', '2152638', '290680', '4342887', '368215', '2028358', '2641307', '282329', '27824', '2409338', '1494110', '175600', '2000490', '2377377', '2012330', '602611', '166129', '52921', '465068', '14293', '179778', '2288919', '224440', '211162', '30112', '4955841', '3569806', '93524', '190869', '316630', '487373', '2663533', '3561868', '2057798', '1425650', '18069', '668315', '4362436', '271696', '722137', '1959158', '101433', '1721804', '1212788', '2257567', '23768', '405107', '1996638', '2178230', '2594053', '68540', '374003', '38784', '38786', '310589', '389825', '296492', '1001987', '1237756', '3525162', '2675126', '2065004', '1137433', '2214259', '482167', '1867697', '1308606', '141442', '595221', '28705', '2384071', '613824', '21931', '371849', '2201299', '6367', '2480633', '19633', '1963256', '398086', '571921', '616766', '4657750', '1962477', '80088', '268820', '1001936', '2106165', '1884716', '149682', '26299', '2053369', '833406', '409620', '795290', '130117', '2045570', '28775', '499385', '54419', '4154469', '4406721', '911255', '251543', '523850', '3912946', '1429197', '1475917', '871369', '3960284', '2655992', '372410', '517346', '431056', '2511706', '2389162', '1786247', '640319', '4183803', '381909', '1965870', '452490', '3216582', '26599', '355242', '2482040', '3253363', '1739369', '19889', '138879', '160949', '3803024', '2508151', '2257601', '964444', '1670311', '4883059', '22481', '590608', '3151684', '129422', '49924', '118103', '402279', '2646368', '100049', '1195220', '2178377', '116029', '1689', '1962596', '100042', '4456286', '115653', '4576322', '485808', '1778987', '17474', '2226712', '99311', '406924', '291598', '2034919', '648374', '187085', '65418', '1797518', '4161711', '2159385', '3758890', '2017862', '702691', '360392', '2604353', '199179', '78656', '119881', '76002', '99945', '869', '2393270', '1347955', '2856801', '366429', '481533', '5011862', '2012449', '620267', '4177548', '305666', '139108', '513142', '654051', '437878', '651839', '206650', '409549', '1962137', '42191', '187395', '5009416', '1408522', '1444475', '485740', '2219338', '1240849', '1383', '1425960', '2120951', '586977', '834480', '3781825', '157112', '670691', '2418762', '474419', '2985232', '521572', '1708831', '3201650', '1425455', '360734', '246783', '2879872', '3053220', '51045', '3478684', '169785', '230404', '327615', '91135', '81693', '92937', '24083', '439046', '445671', '3461676', '414236', '296112', '560216', '3461679', '563322', '1906105', '18575', '1962640', '1802220', '772728', '8699', '999995', '3737422', '191339', '4173659', '81285', '3378149', '57275', '2823295', '150692', '213831', '100884', '1870154', '599436', '494790', '1127439', '182538', '2606610', '135163', '2330764', '113109', '4322876', '417435', '1746161', '153719', '533465', '1034', '1781674', '2512300', '2016427', '3349114', '4173158', '3111727', '1779133', '53050', '409505', '620387', '4054', '1996396', '409501', '409119', '1829683', '321862', '305740', '1194974', '677304', '3636223', '207745', '1726658', '79933', '106909', '270323', '2467570', '81676', '292665', '156406', '3521724', '1960922', '5099203', '1713504', '1870921', '1198553', '1051550', '996997', '488752', '368152', '2755647', '2554698', '618879', '1909706', '289005', '165061', '8561', '4054309', '3860505', '3901959', '1889066', '1869781', '38446', '409611', '30891', '1388012', '409619', '221294', '4086347', '152289', '334819', '1501513', '473104', '2013018', '45347', '285790', '65148', '2169258', '47978', '734072', '2406257', '1898687', '1907919', '2082934', '389015', '23351', '145231', '29626', '2115749', '4271156', '4023222', '1950500', '100643', '2667082', '187467', '799034', '2224951', '422979', '359096', '703517', '3877019', '179506', '4739420', '2442126', '443130', '2188191', '153687', '1231374', '181135', '447903', '837425', '61954', '58305', '2815098', '2257596', '68982', '3218362', '452630', '41197', '88164', '718810', '4542719', '2748195', '1623274', '1679', '279849', '1425236', '169004', '2191263', '66391', '1934254', '4305288', '4812440', '4962622', '19862', '1376118', '2818856', '62133', '637764', '1779679', '357573', '158555', '175058', '307520', '24917', '605672', '579841', '2814377', '673788', '3298060', '1502249', '530097', '1475584', '52797', '1988331', '2462466', '60744', '1758669', '402624', '5164', '4351550', '2294536', '67862', '1225139', '625524', '206625', '3524812', '1916530', '4792851', '640756', '3402346', '217070', '236172', '4318902', '2362502', '1246499', '170672', '63107', '1069176', '3573696', '2678799', '1916791', '496920', '1663783', '2673748', '2109001', '1424293', '27011', '84681', '1725973', '4146621', '236651', '50118', '933941', '74937', '1778799', '2017426', '1211611', '2644389', '197884', '1326885', '532808', '154691', '1418137', '181232', '470151', '2460384', '9034', '1881064', '1080494', '1933856', '401813', '1943392', '1556219', '2035184', '2073126', '86080', '2893052', '105191', '110263', '3461680', '933797', '846445', '4788', '354704', '1851008', '2810683', '1868865', '3778738', '164074', '2049068', '2978220', '280487', '108403', '5115887', '74295', '81204', '58469', '140746', '85218', '1757436', '2845963', '2374509', '1355520', '398472', '232126', '42123', '137651', '3526564', '2129935', '3461612', '1781546', '967119', '584850', '2412184', '69607', '729', '451048', '4375102', '4363', '1928400', '620608', '46054', '2127825', '632378', '729771', '244754', '409514', '36080', '1137518', '2416138', '307200', '3538037', '28378', '2154001', '957', '85280', '630391', '1815394', '129614', '1684006', '1624486', '4552415', '521684', '1976504', '4063664', '2501310', '128017', '345449', '2407850', '3404658', '3959961', '1750383', '975424', '2619595', '1211653', '605136', '2481934', '433472', '24403', '92274', '85140', '379817', '4931698', '1963851', '53964', '139856', '3708955', '458202', '2975978', '1469704', '1722904', '167417', '339581'])\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "filename = 'boston.osm'\n",
    "\n",
    "def test(): \n",
    "    users = set()\n",
    "    for _,element in ET.iterparse(filename):\n",
    "        if 'uid' in element.attrib:\n",
    "            users.add(element.get('uid'))\n",
    "    print \"Count of Unique Users:\", (len(users))\n",
    "    print (users)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Auditing (contd)\n",
    "## Identifying the Count of Unique Users (based on Users) \n",
    "This test is very similar to the test done above, the only difference is that instead of using the UID element we are using the USER element. The test is done to be sure that the results are the same. In both the tests we notice that the counts are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848\n",
      "set(['maxmetcalfe', 'Roger Neumann', 'dloutzen', 'TuftsReady', 'Matej Cepl', 'Steven Deeds', 'Brett Camper', 'noobi', 'Thia564', 'signed0', 'iandees', 'OSMF Redaction Account', 'pcs14', 'scs', 'YunmoW', 'RichRico', 'xybot', 'genuinejack', 'Feddy Pariona Rojas', 'jraviles', 'aonline1', 'ramyaragupathy', 'Mashin', 'phyzome', 'cgu66', 'pierlux', 'Miselajus', 'Manu1400', 'moyogo', 'yurasi', 'smita1', 'gameboo', 'jborthwick', 'maxerickson', 'digdesign', 'cowsandmilk', 'tmcw', 'marnen', 'jak119', 'sivan00', 'smithbone', 'pilotrobert', 'TheDimka', 'Htg610', 'Asumu Takikawa', 'mattbert', 'paolodepetrillo', 'lm0nster', 'Ivanaf', 'Joshua Gerber', 'pezespe', 'Chris Paci', 'db248', 'trsmith', 'wolfgang8741', 'EricTufts', 'Manuel Aristaran', 'beweta', 'Ahlzen', 'kumarhk', 'dfieldsarlington', '42429', 'afreeman', 'minewman', '0123456789', 'virtualxtc', 'Bill Ricker', 'Eliyak', 'Carnildo', 'srajkovic', 'willber118', 'Roadsguy', 'Latze', 'oldtopos', 'Sudip Chandra Paudel', 'woodpeck_repair', 'John-Nicholas Furst', 'sarhs440', 'geodreieck4711', 'hidunno', 'Dan Wood', 'jonaz', 'suuuuurge', 'randomintsolo', 'jforbess', 'mbourqui', 'gsteinmon', 'ediyes', 'cambridgecleanersm', 'RauvinJ', 'Holiday Inn Express Hotel & Suites Boston Garden', 'pollyanna', 'Jon Shea', '1248', 'zEEs', u'Beno\\xeet Prieur', 'dokam', 'uboot', 'Bryce C Nesbitt', 'bmyren', 'Ben Alvord', 'thisss', 'Gabriel Ehrnst Grundin', 'marinero', 'FHOResearch', 'skorbut', 'Chris King', 'aroach', 'Nasrath Faisal', 'ptaff', 'CarlYeks', 'matthieun', 'MaxVT', 'rhavens', 'hanoj', 'jjkindy', 'Dave Breeding', 'JamesFNomar', 'Marcus PS', 'TWRE', 'MikeN', 'mrw6060', 'Vova Kuznetsov', 'richardpetithory', 'ChrisZontine', 'jwass', 'bnewbold', 'grtm', 'agloe', 'hofoen', 'alojmm', 'ScipioA', 'StreamingMeemee', 'Ropino', 'jdm', 'Saul Tannenbaum', 'ruthmaben', 'ettob', 'arajewelers', 'h4ck3rm1k3', 'nfgusedautoparts', u'Vincent D\\xe9m', 'ereuss', 'Evan Jones', 'redsteakraw', 'Tomash Pilshchik', 'simlox', 'PA94', 'lckr', 'ybensadoun', 'Federico Mena Quintero', 'FredRi', 'Roger Zurawicki', 'nicole_thalia', 'Steven Vance', 'eugenebata', 'buna', u'Walter Schl\\xf6gl', 'ethelmermaid', 'rmikke', 'Olyon', 'dbaron', 'Doug0', 'Glassman', 'ChogyDan', 'Benito9', 'dalek2point3', 'abel801', 'Extant', '3ric', 'JasonM1', 'davidearl', 'Paul Knight', 'dchiles', 'Evan82', 'PeterEastern', 'wheelmap_visitor', 'Mafketel', 'Curodo', 'OceanVortex', 'robgeb', 'marcodena', 'srevilak', 'korytaacheck', 'lsweenstar', 'osm2xp', 'Maynewoods', 'mh00', 'aroundi', 'VinceTraveller', 'Jake Strine', 'mueschel', 'RetiredInNH', 'Bill Allen', 'KHGB', 'ganka', 'David Quinn', 'EvanMula', 'vVvA', 'daysigomez13', 'mosu84', 'cbIxDDJp6rQ', 'amadels', 'oini', 'patch615', 'xunilOS', 'Jim Kogler', 'amillar', 'quantumwell', 'sudozero', 'dbzhao', 'Phippen', 'EchoDitto', 'gcamp', 'youfu', 'smacmillan', 'Raj Singh', 'domdomegg', 'EricSJ', 'pluton_od', 'thazel', 'Tobias Stundl', 'nimapper', 'njaard', 'theadkgroup', 'tyrian', 'cmlja', 'Sonzai', 'irumac00', 'MilaZ', 'wambag', 'SunetraB', 'jbecker85', 'Tom Walsh', 'Darqonomous', 'Bobby-Fischer', 'Stemby', 'nibr', 'ingalls_imports', 'Dami_Tn', 'Jothirnadh', 'winsto99', 'ubermonkey79', 'Raq929', 'Copley Square Hotel', 'jonesydesign', 'abschiff', 'JulienBalas', 'farski', 'vkungys', 'Sat', 'yngmthrs', 'DavidZ', 'kreycik', 'teddythebeta', 'StellanL', 'Michael Harnois', 'jremillard', 'Username2', 'Sanjak', 'zenhack', 'Brian Bellah', 'bemasc', 'bbmiller', 'margonotmango', 'winlong', 'richlv', 'Unusual User Name', 'bassettsj', 'Alan Trick', 'dominastrum', 'Retail Technology Group', 'phut', 'One_Ironaut', 'mvexel', 'akweykan', 'tixuwuoz', 'Higonnet', 'rebeccaboofox', 'Jessica Allan Schmidt', 'gregsharp', 'SveNss0N', 'pokey', 'Bob Leigh', 'Brian Stalder', 'Owen Jennings', 'quentin', 'Benjamin Berklee', 'Gile Beye', 'must1n', 'dedwards8', 'massDOT', 'anarcat', 'redsquareblack', 'Michael Cutillo', 'elbatrop', 'Jonathan ZHAO', 'jwsh', 'Paul Fisher', 'BradBarnett', 'Chris Rodger', 'Harry Cutts', 'anonymous58492', 'Gregory Boyce', 'roderickb', 'Gone', 'ejegg', 'synack', 'lesko987', 'Greg Johnston', 'NayanataraM', 'StanB', 'wakeldan', 'liryon', 'pgf', 'adjuva', 'stevens', 'feranick', 'egore911', 'MetaMonk', '_Mathieu_', 'autonomy', 'Johnny Mapperseed', 'dxanato', 'Ethan Stern', 'steverumizen', 'YamaOfParadise', 'mbiker', 'pratikyadav', 'breen', 'millerwachman', 'sanschag', 'Rondale', 'GoWestTravel', 'drbobx', 'fuzzyjoel', 'Jason Carreiro', 'Chanwoo', 'MDIV', 'tyos', 'Aldaron', 'mjfoster83', 'williamp', 'Anthony Moffa', 'Michael J Gilbert', 'MJFC', 'Alps Pierrat', 'fx99', 'cdkii', 'rockfender', 'kellyb', 'philipmolloy', 'rosieks', 'AbaddonPR', 'asmithmd1', 'Wololo', 'ubermonkey', 'almiki', 'MorrisMK', 'RDP3', 'mzaa', u'\\u0410\\u043b\\u0435\\u043a\\u0441\\u0435\\u0439 \\u041a\\u043b\\u044e\\u0447\\u043d\\u0438\\u043a', 'bawdy_bookworm', 'Craig Newell', 'Rouge568', 'Jano John Akim Franke', 'themiurgo', 'bleesand', 'Sarkis Shirinyan', 'KindredCoda', 'saikofish', 'AlaskaDave', 'Warren76', 'Maskulinum', 'mikexstudios', 'Hayboy', 'ngallahe', 'CitymapperHQ', 'colindt', 'thetornado76', 'The Big O Face', 'mvfer', 'ryebread', 'didi_o', 'TylerMills', 'bburt33', 'techlady', 'flierfy', 'Shannon Kelly', 'PlaneMad', 'maggot27', 'mackerski', 'srividya_c', 'Syl', 'HolgerJeromin', 'greta', 'craftsbury', 'Claumires', 'shravan91', 'mazugrin', 'spaceeinstein', 'Bill McAvinney', 'joelbikesalot', 'wward', 'Manfredo Corado', 'RRizman', 'MahaNM', 'Rightlegpegged', 'novikoffav', 'BenCook', 'eriosw', 'onurozgun', 'Alan97', 'colorcraft', 'gknisely', \"Ethan O'Connor\", 'ridixcr', 'RussNelson', 'Daniel Jalkut', 'Travis Bashir', 'Omnific', 'Christoph Lotz', 'blablubb1234', 'syzygyosm', 'chunkywater', 'jcustin', 'theurbanmapper', 'hkelly', 'Cartophiliac', 'paulrosenzweig', 'schoolofgroove', 'djsnaxz', 'tko', 'osm-sputnik', 'ipartola', 'Chetan_Gowda', 'geozeisig', 'paracetamolo', 'trmack2004', 'joshk', 'mmaug', 'Samuel Ekakurniawan', 'mprojekt', 'Dero Bike Racks', 'Sigi Reich', 'karitotp', 'Louis Galvez III', 'Stephen Peters', 'Nothlit', 'Patrick Greenwell', 'brogo', 'viiskis', 'kalanz', 'probiscus', 'Sara Beth', 'SCSpaeth', 'Test360', 'ansoncfit', 'Matthew Miller', 'ighare', 'Luis Capelo', 'Peter A', 'Ryan Berdeen', 'Tom Morris', 'Faith Pastor', 'grossing', 'tjon', 'clairehhlin', 'Mike Linksvayer', 'kinefuchi', 'cdavila', 'claysmalley', 'TarlaMoede', 'evanlgray', 'Larry Stone', 'dlanznar', 'Charles Bandes', 'crschmidt', 'Evan Danaher', 'wdonovan', 'hmvr', 'Michael Williams', 'Milton Bevington', 'Alan Bragg', 'jc67', 'Eyas', 'drjat42', 'Dave330', 'Jac Beattie', 'Pete Robie', 'dannykath', 'onlynone', 'Carl Seglem', 'nickizd', 'Christopher Beland', 'DavidSh', 'cuttothechasse', 'DougPeterson', 'FloppusMaximus', 'nck154', 'AMEDL', 'Benoit Thiell', 'wiso', 'dantje', 'rickmastfan67', 'irenedelatorre', 'Abbe98', 'Yunjie', 'Ian McIntosh', 'wmann', 'brianegge', 'JeffTakle', 'theavclub', 'Jonah', 'SomeoneElse_Revert', 'GeoservicesFDFA', 'MyWayOrNoHighway', 'Echo Echo', 'Sean-of-the-GIS', 'MichelleM123', 'verhovzeva', 'James Michael DuPont', 'EricBell', 'andygol', 'emacsen', 'Constable', 'isabellekh', 'Jeremy Quanno', 'Janjko', 'mapmeld', 'Anders Brownworth', 'DanX', 'pbhade91', 'Gordon2485', 'Aleks-Berlin', 'Iowa Kid', 'Rory Nealon', 'GregCh', 'dph', 'sankeytm', 'lipoff', 'BostonEnginerd', 'LogicalViolinist', 'ravn', 'Jimber', 'Valentino-46', 'fiveisalive', 'borazslo', 'alester', 'erik schlegel', 'Dishaan Ahuja', 'giovanni berlanda', 'jleedev', 'VMeyer', 'kxra', 'hno2', 'ThaBou', 'GerGel', 'charles92', 'ITMarketweb', 'mregan', 'Alexey Lukin', 'Luis36995', 'bannus', 'Hope Chen', 'pkoby', 'JessAk71', 'm3232', 'calfarome', 'SK53', 'cmayne', 'FedericoCozzi', 'mapper999', 'zacmccormick', 'Jens Klein', 'PJorg', 'Ron Newman', 'rjmunro', 'tuttlesclean', 'atannen', 'user_599436', 'Torfason', 'dannya222', 'dennismc', 'Cato_d_Ae', 'imbw267', 'cosmicduck', 'JasonWoof', 'jacobolus', 'bxhrz', 'SWF8', '715371', 'David Posey', 'nygren', 'Teole', 'Rohan Mehra', 'Ailish', 'Andre Engels', 'MrtnMcc', 'elle_dubs', 'ajsalix', 'sejohnson', 'Andrew Varnerin', 'iSKUNK!', 'bucs3282', 'erjiang', 'kingd90', 'slw2014', 'T_9er', 'samely', 'Tim BL', 'jkw', 'sirmmo', 'wfox', 'VKW', 'gutelius', 'doak', 'Mackenzi Coan', 'morganwahl', 'CambridgeRes', 'Utible', 'gavra', 'Peter Dobratz', 'Dean Covert', 'Rollidave', 'Uncle Mango', 'nkhall', 'Thibaut75011', 'massimo_tassi', 'macadoo212', 'john abbott', 'nassive palmer', 'gdt', 'RobertBoston', 'tdtsystem1965', 'Aredhel', 'jlev', 'cmurtaugh', 'Josef73', 'jfarid27', 'tylerritchie', 'myersj', 'Ian Connor', 'ShankarV', 'npettiaux', 'van Rees', 'compdude', 'Shanika Hettige', 'NixG-D', 'Gregory Arenius', 'TomStopka', 'CRichmond', 'Dr Kludge', 'Carlos Tirado', '3yoda', 'jumbanho', 'Bill Witts', 'cditze', 'amm', 'mburt', 'eemikula', 'dru1138', 'rorybecker', 'rodonn', 'eric22', 'Davlak', 'eduardosl', 'hlieberman', u'Kom\\u044fpa', 'iHead', 'kzmijew', 'sammadden', 'JuanBorre', 'LinusA', 'werner2101', 'wsloand', 'BeeeDeee', 'TBHA', 'SophoM', 'salix01', 'andrewpmk', 'Speight', 'BugBuster', 'Campus Planner', 'inertial_circles', 'drsewell426', 'wandsecacher', 'Flitzpiepe', 'jokeefe', 'HHilton', 'Pouletic', 'bigspiral', 'Prithason', 'bdiscoe', 'danrassi', 'radumas', 'Phong Thai Cao', 'keeeto', 'user_1425650', 'jlicht', 'gradient_drift', 'wlgann', 'Med', 'kisaa', 'Kent Johnson', 'HungryCharlie', 'Hegewe01', 'JeffMG', 'krauszerr', 'kgradow1', 'FrankCam', 'OSC', 'jgt', 'tosseto', 'jamacho', 'landfahrer', 'steinmi', 'ioptio', 'SP!KE', 'oba510', 'ervano', 'wvdp', 'Claudius Henrichs', 'GrollTech', 'Andex', 'KEELEY6', 'mterry', 'sfn', 'lakain', 'Shred Nations', 'jremillard-massgis', 'nyuriks', 'kennedyneil', 'Blobo123', 'andreasviglakis', 'Zandlopertje', 'jthandle', 'draiz89', 'brandlebob', 'Katie Baker', 'AndiG88', 'Markus59', 'Parcanman', 'ewedistrict', 'Evan Morikawa', 'tirerim', 'ceyockey', 'arjunkmohan', 'DrMORO', 'user_5359', 'PHerison', 'stevea', 'CloCkWeRX', 'TheC4pt', 'emilypbernier', 'basalt51', 'thomergil', 'meggle', 'RD1', 'reverend_paco', 'celosia', 'tamaa', 'Hyatt Regency Boston', 'Kurly', 'KaleenaSawyer', 'Michael Hohensee', 'boojum99', 'The Liberty Hotel', 'Yoshinion', u'Dauerl\\xe4ufer', 'sujanrajjoshi', 'tomk11', 'mcgrathj', 'shfishburn', 'cspanring', 'ChrissW-R1', 'youngbasedallah', 'bigfoolio', 'woodpeck', 'sph2', 'WonderlustKing', 'GerdP', 'Miriam R', 'dhgoldberg', 'cammls', 'MichaelTerner', 'hopet', 'maximerischard', 'jdalco', 'jamessan', 'rad1ance', 'piligab', 'Pmz', 'ndavidow', 'gremio', 'Brian Ristuccia', 'Gabridoodle', 'motlib', 'nickdoesdevelopment', 'NE2', 'NE3', 'GeoStudent', 'lmum', 'awoodruff', 'headwatersolver', 'bkrausz', 'mapper117', 'PansenkinT', 'kirsanov', 'eklee0120', 'Firozkhan3', 'R0bst3r', 'JP-Motus', 'garyg', 'leebier', 'MassGIS Import', 'H4rr1s0n', 'Trex2001', 'Rub21', 'JohnAKeith', 'jcd', 'Hawkeye', 'Niels Elgaard Larsen', 'TomHynes', 'ari277', 'pcaurorep', 'SGB', 'mkcabgfx', 'Joe Carreiro', 'CycleStreets', 'choess', 'Geogast', 'KristenK', 'jinalfoflia', 'Paul Berry', 'Sarvihepo', 'FrViPofm', 'aarthy', 'ljjwfr', 'Shidash', 'unitelcompany', 'ssbostonmap', 'RMap1', 'RMap3', 'RMap2', 'wenhoe', 't-i', 'makoshark'])\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "filename = 'boston.osm'\n",
    "\n",
    "def test(): \n",
    "    users = set()\n",
    "    for _,element in ET.iterparse(filename):\n",
    "        if 'user' in element.attrib:\n",
    "            users.add(element.get('user'))\n",
    "    print len(users)\n",
    "    print users\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Auditing (Contd) \n",
    "## User Contribution Count: \n",
    "\n",
    "The purpose of this audit is to identify the number of times a specific user has contributed to the map. This test was done to just get an assessment of the top contribution numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('crschmidt', 269245),\n",
      " ('jremillard-massgis', 64989),\n",
      " ('wambag', 29490),\n",
      " ('OceanVortex', 27828),\n",
      " ('ryebread', 21770),\n",
      " ('morganwahl', 20412),\n",
      " ('mapper999', 8315),\n",
      " ('cspanring', 6817),\n",
      " ('JasonWoof', 5445),\n",
      " ('synack', 5054),\n",
      " ('ingalls_imports', 4166),\n",
      " ('Alexey Lukin', 3516),\n",
      " ('fiveisalive', 3145),\n",
      " ('MassGIS Import', 3115),\n",
      " ('Utible', 2872),\n",
      " ('probiscus', 1779),\n",
      " ('Prithason', 1439),\n",
      " ('phyzome', 1409),\n",
      " ('Extant', 1193),\n",
      " ('Alan Bragg', 1171),\n",
      " ('massDOT', 1167),\n",
      " ('Steven Deeds', 1124),\n",
      " ('pkoby', 1090),\n",
      " ('Ahlzen', 1080),\n",
      " ('thetornado76', 955),\n",
      " ('JessAk71', 953),\n",
      " ('3yoda', 890),\n",
      " ('jokeefe', 881),\n",
      " ('ceyockey', 790),\n",
      " ('woodpeck_repair', 771),\n",
      " ('Aredhel', 731),\n",
      " ('Pouletic', 702),\n",
      " ('jwass', 683),\n",
      " ('mterry', 669),\n",
      " ('dloutzen', 633),\n",
      " ('Peter Dobratz', 585),\n",
      " ('pokey', 574),\n",
      " ('KindredCoda', 553),\n",
      " ('dannya222', 546),\n",
      " ('aroach', 509),\n",
      " ('onurozgun', 504),\n",
      " ('headwatersolver', 464),\n",
      " ('kalanz', 410),\n",
      " ('nimapper', 394),\n",
      " ('Echo Echo', 393),\n",
      " ('nkhall', 382),\n",
      " ('spaceeinstein', 375),\n",
      " ('EricSJ', 353),\n",
      " ('calfarome', 353),\n",
      " ('gdt', 345),\n",
      " ('SophoM', 332),\n",
      " ('eugenebata', 317),\n",
      " ('Jim Kogler', 300),\n",
      " ('mregan', 278),\n",
      " ('DavidZ', 277),\n",
      " ('Parcanman', 277),\n",
      " ('techlady', 272),\n",
      " ('42429', 270),\n",
      " ('gsteinmon', 270),\n",
      " ('MDIV', 270),\n",
      " ('jremillard', 263),\n",
      " ('NE2', 254),\n",
      " ('ridixcr', 250),\n",
      " ('Ian McIntosh', 244),\n",
      " ('RMap1', 234),\n",
      " ('srevilak', 225),\n",
      " ('715371', 225),\n",
      " ('Jothirnadh', 221),\n",
      " ('Shannon Kelly', 221),\n",
      " ('steverumizen', 211),\n",
      " ('user_599436', 208),\n",
      " ('minewman', 205),\n",
      " ('Teole', 197),\n",
      " ('erjiang', 181),\n",
      " ('yurasi', 169),\n",
      " ('dannykath', 166),\n",
      " ('amillar', 162),\n",
      " ('wfox', 158),\n",
      " ('Iowa Kid', 156),\n",
      " ('flierfy', 154),\n",
      " ('Luis36995', 150),\n",
      " ('Larry Stone', 143),\n",
      " ('iandees', 140),\n",
      " ('oldtopos', 131),\n",
      " ('tirerim', 130),\n",
      " ('quantumwell', 126),\n",
      " ('Tim BL', 122),\n",
      " ('Niels Elgaard Larsen', 122),\n",
      " ('ljjwfr', 122),\n",
      " ('JeffMG', 120),\n",
      " ('StellanL', 116),\n",
      " ('dalek2point3', 113),\n",
      " ('wheelmap_visitor', 112),\n",
      " ('mh00', 109),\n",
      " ('maxerickson', 108),\n",
      " ('LinusA', 107),\n",
      " ('ShankarV', 106),\n",
      " ('OSMF Redaction Account', 103),\n",
      " ('JulienBalas', 100),\n",
      " ('claysmalley', 100),\n",
      " ('GeoStudent', 99),\n",
      " ('hopet', 98),\n",
      " ('Geogast', 97),\n",
      " ('Roger Zurawicki', 96),\n",
      " ('Craig Newell', 93),\n",
      " ('jacobolus', 91),\n",
      " ('piligab', 91),\n",
      " ('isabellekh', 90),\n",
      " ('user_1425650', 89),\n",
      " ('AlaskaDave', 87),\n",
      " ('Ron Newman', 85),\n",
      " ('PeterEastern', 83),\n",
      " ('agloe', 82),\n",
      " ('MikeN', 79),\n",
      " ('EvanMula', 79),\n",
      " ('giovanni berlanda', 77),\n",
      " ('rad1ance', 74),\n",
      " ('themiurgo', 73),\n",
      " ('jborthwick', 72),\n",
      " ('ewedistrict', 71),\n",
      " ('stevea', 71),\n",
      " ('MyWayOrNoHighway', 70),\n",
      " ('vkungys', 69),\n",
      " ('MaxVT', 66),\n",
      " ('RichRico', 65),\n",
      " ('TBHA', 65),\n",
      " ('Patrick Greenwell', 64),\n",
      " ('SK53', 64),\n",
      " ('Tom Walsh', 63),\n",
      " ('ediyes', 62),\n",
      " ('stevens', 62),\n",
      " ('breen', 62),\n",
      " ('Rouge568', 62),\n",
      " (\"Ethan O'Connor\", 61),\n",
      " ('karitotp', 61),\n",
      " ('marnen', 59),\n",
      " ('williamp', 58),\n",
      " ('TuftsReady', 57),\n",
      " ('Bill Witts', 57),\n",
      " ('Luis Capelo', 56),\n",
      " ('sankeytm', 55),\n",
      " ('sarhs440', 54),\n",
      " ('fx99', 54),\n",
      " ('Rory Nealon', 54),\n",
      " ('andrewpmk', 53),\n",
      " ('awoodruff', 53),\n",
      " ('robgeb', 52),\n",
      " ('Chanwoo', 52),\n",
      " ('pezespe', 51),\n",
      " ('Alan97', 51),\n",
      " ('jamessan', 51),\n",
      " ('phut', 50),\n",
      " ('garyg', 49),\n",
      " ('jinalfoflia', 49),\n",
      " ('Bryce C Nesbitt', 48),\n",
      " ('kzmijew', 48),\n",
      " ('bigspiral', 48),\n",
      " ('cowsandmilk', 47),\n",
      " ('Claumires', 47),\n",
      " ('wward', 45),\n",
      " ('Bill Ricker', 44),\n",
      " ('pratikyadav', 43),\n",
      " ('GoWestTravel', 43),\n",
      " ('samely', 43),\n",
      " ('SunetraB', 42),\n",
      " ('_Mathieu_', 42),\n",
      " ('ngallahe', 42),\n",
      " ('RD1', 42),\n",
      " ('NixG-D', 41),\n",
      " ('AMEDL', 40),\n",
      " ('nyuriks', 40),\n",
      " ('Anthony Moffa', 37),\n",
      " ('CitymapperHQ', 37),\n",
      " ('andygol', 37),\n",
      " ('jumbanho', 37),\n",
      " ('beweta', 36),\n",
      " ('Dishaan Ahuja', 36),\n",
      " ('bdiscoe', 36),\n",
      " ('jwsh', 35),\n",
      " ('EricTufts', 34),\n",
      " ('hidunno', 34),\n",
      " ('suuuuurge', 34),\n",
      " ('srividya_c', 32),\n",
      " ('Daniel Jalkut', 32),\n",
      " ('pbhade91', 32),\n",
      " ('Kent Johnson', 32),\n",
      " ('Tom Morris', 31),\n",
      " ('sirmmo', 31),\n",
      " ('leebier', 31),\n",
      " ('RussNelson', 30),\n",
      " ('PHerison', 30),\n",
      " ('bannus', 29),\n",
      " ('David Posey', 29),\n",
      " ('iSKUNK!', 28),\n",
      " ('keeeto', 28),\n",
      " ('RMap3', 28),\n",
      " ('radumas', 27),\n",
      " ('andreasviglakis', 27),\n",
      " ('Miriam R', 27),\n",
      " ('Paul Fisher', 26),\n",
      " ('kennedyneil', 26),\n",
      " ('Sat', 25),\n",
      " ('almiki', 25),\n",
      " ('charles92', 25),\n",
      " ('BeeeDeee', 25),\n",
      " ('WonderlustKing', 25),\n",
      " ('lmum', 25),\n",
      " ('KristenK', 25),\n",
      " ('dokam', 24),\n",
      " ('Doug0', 24),\n",
      " ('VMeyer', 24),\n",
      " ('PJorg', 24),\n",
      " ('eduardosl', 24),\n",
      " ('lckr', 22),\n",
      " ('farski', 22),\n",
      " ('One_Ironaut', 22),\n",
      " ('kellyb', 22),\n",
      " ('Maskulinum', 22),\n",
      " ('KEELEY6', 22),\n",
      " ('ChrisZontine', 21),\n",
      " ('cbIxDDJp6rQ', 21),\n",
      " ('dominastrum', 21),\n",
      " ('pgf', 21),\n",
      " ('Ryan Berdeen', 21),\n",
      " ('tjon', 21),\n",
      " ('Dr Kludge', 21),\n",
      " ('user_5359', 21),\n",
      " ('virtualxtc', 20),\n",
      " ('redsteakraw', 20),\n",
      " ('Phong Thai Cao', 20),\n",
      " ('oba510', 20),\n",
      " ('DrMORO', 20),\n",
      " ('dbzhao', 19),\n",
      " ('saikofish', 19),\n",
      " ('ansoncfit', 19),\n",
      " ('Ailish', 19),\n",
      " ('compdude', 19),\n",
      " ('sph2', 19),\n",
      " ('Trex2001', 19),\n",
      " ('David Quinn', 18),\n",
      " ('oini', 17),\n",
      " ('Andex', 17),\n",
      " ('PansenkinT', 17),\n",
      " ('Thia564', 16),\n",
      " ('scs', 16),\n",
      " ('John-Nicholas Furst', 16),\n",
      " ('osm2xp', 16),\n",
      " ('lakain', 16),\n",
      " ('jonaz', 15),\n",
      " ('Vova Kuznetsov', 15),\n",
      " ('bnewbold', 15),\n",
      " ('Saul Tannenbaum', 15),\n",
      " ('paulrosenzweig', 15),\n",
      " ('kinefuchi', 15),\n",
      " ('ajsalix', 15),\n",
      " ('nickdoesdevelopment', 15),\n",
      " ('FredRi', 14),\n",
      " ('Brian Stalder', 14),\n",
      " ('Benjamin Berklee', 14),\n",
      " ('drjat42', 14),\n",
      " ('Med', 14),\n",
      " ('Yoshinion', 14),\n",
      " ('RMap2', 14),\n",
      " ('Asumu Takikawa', 13),\n",
      " ('Sonzai', 13),\n",
      " ('anonymous58492', 13),\n",
      " ('NayanataraM', 13),\n",
      " ('Johnny Mapperseed', 13),\n",
      " ('Warren76', 13),\n",
      " ('grossing', 13),\n",
      " ('nck154', 13),\n",
      " ('wiso', 13),\n",
      " ('GeoservicesFDFA', 13),\n",
      " ('DanX', 13),\n",
      " ('krauszerr', 13),\n",
      " ('Roger Neumann', 12),\n",
      " ('pcs14', 12),\n",
      " ('xybot', 12),\n",
      " ('TheDimka', 12),\n",
      " ('Dan Wood', 12),\n",
      " ('tyrian', 12),\n",
      " ('nibr', 12),\n",
      " ('Chetan_Gowda', 12),\n",
      " ('bxhrz', 12),\n",
      " ('KaleenaSawyer', 12),\n",
      " ('maximerischard', 12),\n",
      " ('Brian Ristuccia', 12),\n",
      " ('0123456789', 11),\n",
      " ('Benito9', 11),\n",
      " ('cdkii', 11),\n",
      " ('DougPeterson', 11),\n",
      " ('Andrew Varnerin', 11),\n",
      " ('gradient_drift', 11),\n",
      " ('aonline1', 10),\n",
      " ('geodreieck4711', 10),\n",
      " ('jdm', 10),\n",
      " ('3ric', 10),\n",
      " ('korytaacheck', 10),\n",
      " ('tyos', 10),\n",
      " ('Benoit Thiell', 10),\n",
      " ('CloCkWeRX', 10),\n",
      " ('Chris Paci', 9),\n",
      " ('srajkovic', 9),\n",
      " ('dchiles', 9),\n",
      " ('winlong', 9),\n",
      " ('PlaneMad', 9),\n",
      " ('syzygyosm', 9),\n",
      " ('onlynone', 9),\n",
      " ('ThaBou', 9),\n",
      " ('macadoo212', 9),\n",
      " ('landfahrer', 9),\n",
      " ('aarthy', 9),\n",
      " ('Olyon', 8),\n",
      " ('abel801', 8),\n",
      " ('RetiredInNH', 8),\n",
      " ('kreycik', 8),\n",
      " ('Gone', 8),\n",
      " ('liryon', 8),\n",
      " ('mjfoster83', 8),\n",
      " ('BenCook', 8),\n",
      " ('paracetamolo', 8),\n",
      " ('mmaug', 8),\n",
      " ('Rollidave', 8),\n",
      " ('RobertBoston', 8),\n",
      " ('eemikula', 8),\n",
      " ('eric22', 8),\n",
      " ('BugBuster', 8),\n",
      " ('OSC', 8),\n",
      " ('Firozkhan3', 8),\n",
      " ('ScipioA', 7),\n",
      " ('lsweenstar', 7),\n",
      " ('KHGB', 7),\n",
      " ('gcamp', 7),\n",
      " ('youfu', 7),\n",
      " ('pluton_od', 7),\n",
      " ('MilaZ', 7),\n",
      " ('jonesydesign', 7),\n",
      " ('Owen Jennings', 7),\n",
      " ('StanB', 7),\n",
      " ('rockfender', 7),\n",
      " ('philipmolloy', 7),\n",
      " ('bburt33', 7),\n",
      " ('eriosw', 7),\n",
      " ('jcustin', 7),\n",
      " ('wdonovan', 7),\n",
      " ('Carl Seglem', 7),\n",
      " ('GerGel', 7),\n",
      " ('Hope Chen', 7),\n",
      " ('Jens Klein', 7),\n",
      " ('gavra', 7),\n",
      " ('Shanika Hettige', 7),\n",
      " ('kisaa', 7),\n",
      " ('TheC4pt', 7),\n",
      " ('Michael Hohensee', 7),\n",
      " ('boojum99', 7),\n",
      " ('ChrissW-R1', 7),\n",
      " ('JohnAKeith', 7),\n",
      " ('YunmoW', 6),\n",
      " ('mattbert', 6),\n",
      " ('afreeman', 6),\n",
      " ('zEEs', 6),\n",
      " ('ptaff', 6),\n",
      " ('hofoen', 6),\n",
      " ('Tomash Pilshchik', 6),\n",
      " ('PA94', 6),\n",
      " ('Gile Beye', 6),\n",
      " ('Michael Cutillo', 6),\n",
      " ('egore911', 6),\n",
      " ('Aldaron', 6),\n",
      " ('trmack2004', 6),\n",
      " ('Nothlit', 6),\n",
      " ('dlanznar', 6),\n",
      " ('hmvr', 6),\n",
      " ('Milton Bevington', 6),\n",
      " ('DavidSh', 6),\n",
      " ('irenedelatorre', 6),\n",
      " ('Abbe98', 6),\n",
      " ('amm', 6),\n",
      " ('sammadden', 6),\n",
      " ('werner2101', 6),\n",
      " ('Speight', 6),\n",
      " ('kgradow1', 6),\n",
      " ('shfishburn', 6),\n",
      " ('mapper117', 6),\n",
      " ('SGB', 6),\n",
      " ('wenhoe', 6),\n",
      " ('paolodepetrillo', 5),\n",
      " ('trsmith', 5),\n",
      " ('Eliyak', 5),\n",
      " ('RauvinJ', 5),\n",
      " ('jjkindy', 5),\n",
      " ('ereuss', 5),\n",
      " ('JasonM1', 5),\n",
      " ('Username2', 5),\n",
      " ('zenhack', 5),\n",
      " ('bbmiller', 5),\n",
      " ('Bob Leigh', 5),\n",
      " ('feranick', 5),\n",
      " ('fuzzyjoel', 5),\n",
      " ('Michael J Gilbert', 5),\n",
      " ('mzaa', 5),\n",
      " (u'\\u0410\\u043b\\u0435\\u043a\\u0441\\u0435\\u0439 \\u041a\\u043b\\u044e\\u0447\\u043d\\u0438\\u043a',\n",
      "  5),\n",
      " ('bawdy_bookworm', 5),\n",
      " ('mvfer', 5),\n",
      " ('hkelly', 5),\n",
      " ('Samuel Ekakurniawan', 5),\n",
      " ('Dero Bike Racks', 5),\n",
      " ('Sara Beth', 5),\n",
      " ('verhovzeva', 5),\n",
      " ('lipoff', 5),\n",
      " ('m3232', 5),\n",
      " ('kingd90', 5),\n",
      " ('tdtsystem1965', 5),\n",
      " ('jlicht', 5),\n",
      " ('HungryCharlie', 5),\n",
      " ('FrankCam', 5),\n",
      " ('tosseto', 5),\n",
      " ('jamacho', 5),\n",
      " ('sfn', 5),\n",
      " ('draiz89', 5),\n",
      " ('kirsanov', 5),\n",
      " ('eklee0120', 5),\n",
      " ('CycleStreets', 5),\n",
      " ('Paul Berry', 5),\n",
      " ('maxmetcalfe', 4),\n",
      " ('signed0', 4),\n",
      " ('pilotrobert', 4),\n",
      " ('wolfgang8741', 4),\n",
      " ('Sudip Chandra Paudel', 4),\n",
      " ('Holiday Inn Express Hotel & Suites Boston Garden', 4),\n",
      " ('marinero', 4),\n",
      " ('FHOResearch', 4),\n",
      " ('CarlYeks', 4),\n",
      " ('rhavens', 4),\n",
      " ('ruthmaben', 4),\n",
      " ('Federico Mena Quintero', 4),\n",
      " ('Steven Vance', 4),\n",
      " ('vVvA', 4),\n",
      " ('xunilOS', 4),\n",
      " ('Phippen', 4),\n",
      " ('Tobias Stundl', 4),\n",
      " ('jbecker85', 4),\n",
      " ('Brian Bellah', 4),\n",
      " ('bemasc', 4),\n",
      " ('bassettsj', 4),\n",
      " ('mvexel', 4),\n",
      " ('autonomy', 4),\n",
      " ('maggot27', 4),\n",
      " ('Stephen Peters', 4),\n",
      " ('Peter A', 4),\n",
      " ('Jonah', 4),\n",
      " ('BostonEnginerd', 4),\n",
      " ('dennismc', 4),\n",
      " ('T_9er', 4),\n",
      " ('Gregory Arenius', 4),\n",
      " ('mburt', 4),\n",
      " ('Hegewe01', 4),\n",
      " ('dhgoldberg', 4),\n",
      " ('gremio', 4),\n",
      " ('choess', 4),\n",
      " ('Mashin', 3),\n",
      " ('jak119', 3),\n",
      " ('Latze', 3),\n",
      " ('Jon Shea', 3),\n",
      " ('alojmm', 3),\n",
      " ('Evan82', 3),\n",
      " ('Maynewoods', 3),\n",
      " ('mosu84', 3),\n",
      " ('Michael Harnois', 3),\n",
      " ('richlv', 3),\n",
      " ('Jessica Allan Schmidt', 3),\n",
      " ('Rondale', 3),\n",
      " ('MorrisMK', 3),\n",
      " ('didi_o', 3),\n",
      " ('craftsbury', 3),\n",
      " ('gknisely', 3),\n",
      " ('joshk', 3),\n",
      " ('Sigi Reich', 3),\n",
      " ('viiskis', 3),\n",
      " ('Pete Robie', 3),\n",
      " ('Christopher Beland', 3),\n",
      " ('Jeremy Quanno', 3),\n",
      " ('Aleks-Berlin', 3),\n",
      " ('Jimber', 3),\n",
      " ('imbw267', 3),\n",
      " ('sejohnson', 3),\n",
      " ('bucs3282', 3),\n",
      " ('slw2014', 3),\n",
      " ('jkw', 3),\n",
      " ('cmurtaugh', 3),\n",
      " ('Carlos Tirado', 3),\n",
      " ('hlieberman', 3),\n",
      " ('JuanBorre', 3),\n",
      " ('wsloand', 3),\n",
      " ('salix01', 3),\n",
      " ('Blobo123', 3),\n",
      " ('jthandle', 3),\n",
      " ('AndiG88', 3),\n",
      " ('basalt51', 3),\n",
      " ('thomergil', 3),\n",
      " ('meggle', 3),\n",
      " ('sujanrajjoshi', 3),\n",
      " ('Rub21', 3),\n",
      " ('Hawkeye', 3),\n",
      " ('Matej Cepl', 2),\n",
      " ('Brett Camper', 2),\n",
      " ('Feddy Pariona Rojas', 2),\n",
      " ('cgu66', 2),\n",
      " ('Manu1400', 2),\n",
      " ('moyogo', 2),\n",
      " ('smita1', 2),\n",
      " ('Ivanaf', 2),\n",
      " ('dfieldsarlington', 2),\n",
      " ('randomintsolo', 2),\n",
      " ('pollyanna', 2),\n",
      " ('uboot', 2),\n",
      " ('thisss', 2),\n",
      " ('Marcus PS', 2),\n",
      " ('grtm', 2),\n",
      " ('Ropino', 2),\n",
      " (u'Vincent D\\xe9m', 2),\n",
      " ('Evan Jones', 2),\n",
      " ('ybensadoun', 2),\n",
      " (u'Walter Schl\\xf6gl', 2),\n",
      " ('davidearl', 2),\n",
      " ('Paul Knight', 2),\n",
      " ('Curodo', 2),\n",
      " ('daysigomez13', 2),\n",
      " ('patch615', 2),\n",
      " ('Raj Singh', 2),\n",
      " ('cmlja', 2),\n",
      " ('Darqonomous', 2),\n",
      " ('Bobby-Fischer', 2),\n",
      " ('Raq929', 2),\n",
      " ('tixuwuoz', 2),\n",
      " ('gregsharp', 2),\n",
      " ('SveNss0N', 2),\n",
      " ('must1n', 2),\n",
      " ('dedwards8', 2),\n",
      " ('Harry Cutts', 2),\n",
      " ('lesko987', 2),\n",
      " ('adjuva', 2),\n",
      " ('dxanato', 2),\n",
      " ('mbiker', 2),\n",
      " ('sanschag', 2),\n",
      " ('AbaddonPR', 2),\n",
      " ('asmithmd1', 2),\n",
      " ('RDP3', 2),\n",
      " ('mackerski', 2),\n",
      " ('Syl', 2),\n",
      " ('HolgerJeromin', 2),\n",
      " ('mazugrin', 2),\n",
      " ('joelbikesalot', 2),\n",
      " ('Manfredo Corado', 2),\n",
      " ('RRizman', 2),\n",
      " ('novikoffav', 2),\n",
      " ('blablubb1234', 2),\n",
      " ('chunkywater', 2),\n",
      " ('tko', 2),\n",
      " ('osm-sputnik', 2),\n",
      " ('Test360', 2),\n",
      " ('Matthew Miller', 2),\n",
      " ('clairehhlin', 2),\n",
      " ('dantje', 2),\n",
      " ('theavclub', 2),\n",
      " ('Sean-of-the-GIS', 2),\n",
      " ('James Michael DuPont', 2),\n",
      " ('Constable', 2),\n",
      " ('Anders Brownworth', 2),\n",
      " ('hno2', 2),\n",
      " ('atannen', 2),\n",
      " ('cosmicduck', 2),\n",
      " ('Rohan Mehra', 2),\n",
      " ('john abbott', 2),\n",
      " ('nassive palmer', 2),\n",
      " ('tylerritchie', 2),\n",
      " ('myersj', 2),\n",
      " ('van Rees', 2),\n",
      " ('CRichmond', 2),\n",
      " ('dru1138', 2),\n",
      " ('rorybecker', 2),\n",
      " ('rodonn', 2),\n",
      " ('ioptio', 2),\n",
      " ('Claudius Henrichs', 2),\n",
      " ('GrollTech', 2),\n",
      " ('Katie Baker', 2),\n",
      " ('Markus59', 2),\n",
      " ('celosia', 2),\n",
      " ('youngbasedallah', 2),\n",
      " ('woodpeck', 2),\n",
      " ('motlib', 2),\n",
      " ('NE3', 2),\n",
      " ('H4rr1s0n', 2),\n",
      " ('TomHynes', 2),\n",
      " ('Sarvihepo', 2),\n",
      " ('FrViPofm', 2),\n",
      " ('noobi', 1),\n",
      " ('genuinejack', 1),\n",
      " ('jraviles', 1),\n",
      " ('ramyaragupathy', 1),\n",
      " ('pierlux', 1),\n",
      " ('Miselajus', 1),\n",
      " ('gameboo', 1),\n",
      " ('digdesign', 1),\n",
      " ('tmcw', 1),\n",
      " ('sivan00', 1),\n",
      " ('smithbone', 1),\n",
      " ('Htg610', 1),\n",
      " ('lm0nster', 1),\n",
      " ('Joshua Gerber', 1),\n",
      " ('db248', 1),\n",
      " ('Manuel Aristaran', 1),\n",
      " ('kumarhk', 1),\n",
      " ('Carnildo', 1),\n",
      " ('willber118', 1),\n",
      " ('Roadsguy', 1),\n",
      " ('jforbess', 1),\n",
      " ('mbourqui', 1),\n",
      " ('cambridgecleanersm', 1),\n",
      " ('1248', 1),\n",
      " (u'Beno\\xeet Prieur', 1),\n",
      " ('bmyren', 1),\n",
      " ('Ben Alvord', 1),\n",
      " ('Gabriel Ehrnst Grundin', 1),\n",
      " ('skorbut', 1),\n",
      " ('Chris King', 1),\n",
      " ('Nasrath Faisal', 1),\n",
      " ('matthieun', 1),\n",
      " ('hanoj', 1),\n",
      " ('Dave Breeding', 1),\n",
      " ('JamesFNomar', 1),\n",
      " ('TWRE', 1),\n",
      " ('mrw6060', 1),\n",
      " ('richardpetithory', 1),\n",
      " ('StreamingMeemee', 1),\n",
      " ('ettob', 1),\n",
      " ('arajewelers', 1),\n",
      " ('h4ck3rm1k3', 1),\n",
      " ('nfgusedautoparts', 1),\n",
      " ('simlox', 1),\n",
      " ('nicole_thalia', 1),\n",
      " ('buna', 1),\n",
      " ('ethelmermaid', 1),\n",
      " ('rmikke', 1),\n",
      " ('dbaron', 1),\n",
      " ('Glassman', 1),\n",
      " ('ChogyDan', 1),\n",
      " ('Mafketel', 1),\n",
      " ('marcodena', 1),\n",
      " ('aroundi', 1),\n",
      " ('VinceTraveller', 1),\n",
      " ('Jake Strine', 1),\n",
      " ('mueschel', 1),\n",
      " ('Bill Allen', 1),\n",
      " ('ganka', 1),\n",
      " ('amadels', 1),\n",
      " ('sudozero', 1),\n",
      " ('EchoDitto', 1),\n",
      " ('smacmillan', 1),\n",
      " ('domdomegg', 1),\n",
      " ('thazel', 1),\n",
      " ('njaard', 1),\n",
      " ('theadkgroup', 1),\n",
      " ('irumac00', 1),\n",
      " ('Stemby', 1),\n",
      " ('Dami_Tn', 1),\n",
      " ('winsto99', 1),\n",
      " ('ubermonkey79', 1),\n",
      " ('Copley Square Hotel', 1),\n",
      " ('abschiff', 1),\n",
      " ('yngmthrs', 1),\n",
      " ('teddythebeta', 1),\n",
      " ('Sanjak', 1),\n",
      " ('margonotmango', 1),\n",
      " ('Unusual User Name', 1),\n",
      " ('Alan Trick', 1),\n",
      " ('Retail Technology Group', 1),\n",
      " ('akweykan', 1),\n",
      " ('Higonnet', 1),\n",
      " ('rebeccaboofox', 1),\n",
      " ('quentin', 1),\n",
      " ('anarcat', 1),\n",
      " ('redsquareblack', 1),\n",
      " ('elbatrop', 1),\n",
      " ('Jonathan ZHAO', 1),\n",
      " ('BradBarnett', 1),\n",
      " ('Chris Rodger', 1),\n",
      " ('Gregory Boyce', 1),\n",
      " ('roderickb', 1),\n",
      " ('ejegg', 1),\n",
      " ('Greg Johnston', 1),\n",
      " ('wakeldan', 1),\n",
      " ('MetaMonk', 1),\n",
      " ('Ethan Stern', 1),\n",
      " ('YamaOfParadise', 1),\n",
      " ('millerwachman', 1),\n",
      " ('drbobx', 1),\n",
      " ('Jason Carreiro', 1),\n",
      " ('MJFC', 1),\n",
      " ('Alps Pierrat', 1),\n",
      " ('rosieks', 1),\n",
      " ('Wololo', 1),\n",
      " ('ubermonkey', 1),\n",
      " ('Jano John Akim Franke', 1),\n",
      " ('bleesand', 1),\n",
      " ('Sarkis Shirinyan', 1),\n",
      " ('mikexstudios', 1),\n",
      " ('Hayboy', 1),\n",
      " ('colindt', 1),\n",
      " ('The Big O Face', 1),\n",
      " ('TylerMills', 1),\n",
      " ('greta', 1),\n",
      " ('shravan91', 1),\n",
      " ('Bill McAvinney', 1),\n",
      " ('MahaNM', 1),\n",
      " ('Rightlegpegged', 1),\n",
      " ('colorcraft', 1),\n",
      " ('Travis Bashir', 1),\n",
      " ('Omnific', 1),\n",
      " ('Christoph Lotz', 1),\n",
      " ('theurbanmapper', 1),\n",
      " ('Cartophiliac', 1),\n",
      " ('schoolofgroove', 1),\n",
      " ('djsnaxz', 1),\n",
      " ('ipartola', 1),\n",
      " ('geozeisig', 1),\n",
      " ('mprojekt', 1),\n",
      " ('Louis Galvez III', 1),\n",
      " ('brogo', 1),\n",
      " ('SCSpaeth', 1),\n",
      " ('ighare', 1),\n",
      " ('Faith Pastor', 1),\n",
      " ('Mike Linksvayer', 1),\n",
      " ('cdavila', 1),\n",
      " ('TarlaMoede', 1),\n",
      " ('evanlgray', 1),\n",
      " ('Charles Bandes', 1),\n",
      " ('Evan Danaher', 1),\n",
      " ('Michael Williams', 1),\n",
      " ('jc67', 1),\n",
      " ('Eyas', 1),\n",
      " ('Dave330', 1),\n",
      " ('Jac Beattie', 1),\n",
      " ('nickizd', 1),\n",
      " ('cuttothechasse', 1),\n",
      " ('FloppusMaximus', 1),\n",
      " ('rickmastfan67', 1),\n",
      " ('Yunjie', 1),\n",
      " ('wmann', 1),\n",
      " ('brianegge', 1),\n",
      " ('JeffTakle', 1),\n",
      " ('SomeoneElse_Revert', 1),\n",
      " ('MichelleM123', 1),\n",
      " ('EricBell', 1),\n",
      " ('emacsen', 1),\n",
      " ('Janjko', 1),\n",
      " ('mapmeld', 1),\n",
      " ('Gordon2485', 1),\n",
      " ('GregCh', 1),\n",
      " ('dph', 1),\n",
      " ('LogicalViolinist', 1),\n",
      " ('ravn', 1),\n",
      " ('Valentino-46', 1),\n",
      " ('borazslo', 1),\n",
      " ('alester', 1),\n",
      " ('erik schlegel', 1),\n",
      " ('jleedev', 1),\n",
      " ('kxra', 1),\n",
      " ('ITMarketweb', 1),\n",
      " ('cmayne', 1),\n",
      " ('FedericoCozzi', 1),\n",
      " ('zacmccormick', 1),\n",
      " ('rjmunro', 1),\n",
      " ('tuttlesclean', 1),\n",
      " ('Torfason', 1),\n",
      " ('Cato_d_Ae', 1),\n",
      " ('SWF8', 1),\n",
      " ('nygren', 1),\n",
      " ('Andre Engels', 1),\n",
      " ('MrtnMcc', 1),\n",
      " ('elle_dubs', 1),\n",
      " ('VKW', 1),\n",
      " ('gutelius', 1),\n",
      " ('doak', 1),\n",
      " ('Mackenzi Coan', 1),\n",
      " ('CambridgeRes', 1),\n",
      " ('Dean Covert', 1),\n",
      " ('Uncle Mango', 1),\n",
      " ('Thibaut75011', 1),\n",
      " ('massimo_tassi', 1),\n",
      " ('jlev', 1),\n",
      " ('Josef73', 1),\n",
      " ('jfarid27', 1),\n",
      " ('Ian Connor', 1),\n",
      " ('npettiaux', 1),\n",
      " ('TomStopka', 1),\n",
      " ('cditze', 1),\n",
      " ('Davlak', 1),\n",
      " (u'Kom\\u044fpa', 1),\n",
      " ('iHead', 1),\n",
      " ('Campus Planner', 1),\n",
      " ('inertial_circles', 1),\n",
      " ('drsewell426', 1),\n",
      " ('wandsecacher', 1),\n",
      " ('Flitzpiepe', 1),\n",
      " ('HHilton', 1),\n",
      " ('danrassi', 1),\n",
      " ('wlgann', 1),\n",
      " ('jgt', 1),\n",
      " ('steinmi', 1),\n",
      " ('SP!KE', 1),\n",
      " ('ervano', 1),\n",
      " ('wvdp', 1),\n",
      " ('Shred Nations', 1),\n",
      " ('Zandlopertje', 1),\n",
      " ('brandlebob', 1),\n",
      " ('Evan Morikawa', 1),\n",
      " ('arjunkmohan', 1),\n",
      " ('emilypbernier', 1),\n",
      " ('reverend_paco', 1),\n",
      " ('tamaa', 1),\n",
      " ('Hyatt Regency Boston', 1),\n",
      " ('Kurly', 1),\n",
      " ('The Liberty Hotel', 1),\n",
      " (u'Dauerl\\xe4ufer', 1),\n",
      " ('tomk11', 1),\n",
      " ('mcgrathj', 1),\n",
      " ('bigfoolio', 1),\n",
      " ('GerdP', 1),\n",
      " ('cammls', 1),\n",
      " ('MichaelTerner', 1),\n",
      " ('jdalco', 1),\n",
      " ('Pmz', 1),\n",
      " ('ndavidow', 1),\n",
      " ('Gabridoodle', 1),\n",
      " ('bkrausz', 1),\n",
      " ('R0bst3r', 1),\n",
      " ('JP-Motus', 1),\n",
      " ('jcd', 1),\n",
      " ('ari277', 1),\n",
      " ('pcaurorep', 1),\n",
      " ('mkcabgfx', 1),\n",
      " ('Joe Carreiro', 1),\n",
      " ('Shidash', 1),\n",
      " ('unitelcompany', 1),\n",
      " ('ssbostonmap', 1),\n",
      " ('t-i', 1),\n",
      " ('makoshark', 1)]\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import codecs\n",
    "import json\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "\n",
    "filename = 'boston.osm'\n",
    "\n",
    "def test(): \n",
    "    user_list = []\n",
    "    user_dict = defaultdict(int)\n",
    "    for _,element in ET.iterparse(filename):\n",
    "        if 'user' in element.attrib:\n",
    "            user_list.append(element.get('user'))\n",
    "        else: \n",
    "            continue\n",
    "    \n",
    "    for item in user_list: \n",
    "        user_dict[item] +=1 \n",
    "    sorted_user_dict = sorted(user_dict.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    pprint.pprint(sorted_user_dict)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The top ten contributors based on the results of the output above:**\n",
    "[('crschmidt', 269245),\n",
    " ('jremillard-massgis', 64989),\n",
    " ('wambag', 29490),\n",
    " ('OceanVortex', 27828),\n",
    " ('ryebread', 21770),\n",
    " ('morganwahl', 20412),\n",
    " ('mapper999', 8315),\n",
    " ('cspanring', 6817),\n",
    " ('JasonWoof', 5445),\n",
    " ('synack', 5054)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Auditing (contd)\n",
    "## This step involves auditing the value of the addr tags for \n",
    "\n",
    "1. Lower Case Characters \n",
    "2. Lower Case Characters with Colon \n",
    "3. Problematic Characters \n",
    "\n",
    "The final output includes a dictionary with keys for each of the category and the count of values for each of the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {'problemchars': 3332, 'lower': 83, 'other': 8195})\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "filename = 'boston.osm'\n",
    "\n",
    "\n",
    "def process_address(addr_value):\n",
    "    if re.search(lower,addr_value):\n",
    "        keys['lower'] += 1\n",
    "    elif re.search(lower_colon, addr_value): \n",
    "        keys['lower_colon'] += 1\n",
    "    elif re.search(problemchars, addr_value): \n",
    "        keys['problemchars'] += 1 \n",
    "    else: \n",
    "        keys['other'] += 1\n",
    "                \n",
    "\n",
    "def read_file():\n",
    "    for _, element in ET.iterparse(filename): \n",
    "        if element.tag == 'tag': \n",
    "            key=element.get('k')\n",
    "            if 'addr:' in key:\n",
    "                addr_value = element.get('v')\n",
    "                process_address(addr_value)\n",
    "    return keys\n",
    "                    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    keys = defaultdict(int)\n",
    "    read_key = read_file()\n",
    "    print read_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Auditing (contd) \n",
    "## Auditing Street Names and Identifying Anomalies\n",
    "This step involves auditing the street names for the last element in the string name. Identifying the last element in street name is done via regular expression. \n",
    "\n",
    "The psuedocode involves comparing this \"last element value\" in the street name with list of expected elements in the \"expected\" list. If the \"last element value\" is not found in the expected list, the element is added to the dictionary as key along with the associated street name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1100': set(['First Street, Suite 1100']),\n",
      " '1302': set(['Cambridge Street #1302']),\n",
      " '3': set(['Kendall Square - 3']),\n",
      " '303': set(['First Street, Suite 303']),\n",
      " '501': set(['Bromfield Street #501']),\n",
      " '6': set(['South Station, near Track 6']),\n",
      " '846028': set(['PO Box 846028']),\n",
      " 'Ave': set(['738 Commonwealth Ave',\n",
      "             'Boston Ave',\n",
      "             'College Ave',\n",
      "             'Commonwealth Ave',\n",
      "             'Concord Ave',\n",
      "             'Francesca Ave',\n",
      "             'Highland Ave',\n",
      "             'Josephine Ave',\n",
      "             'Lexington Ave',\n",
      "             'Massachusetts Ave',\n",
      "             'Morrison Ave',\n",
      "             'Mystic Ave',\n",
      "             'Somerville Ave',\n",
      "             'Western Ave',\n",
      "             'Willow Ave']),\n",
      " 'Ave.': set(['Brighton Ave.',\n",
      "              'Massachusetts Ave.',\n",
      "              'Somerville Ave.',\n",
      "              'Spaulding Ave.']),\n",
      " 'Broadway': set(['Broadway']),\n",
      " 'Cambrdige': set(['Cambrdige']),\n",
      " 'Center': set(['Cambridge Center', 'Financial Center']),\n",
      " 'Circle': set(['Norcross Circle']),\n",
      " 'Ct': set(['Kelley Ct']),\n",
      " 'Driveway': set(['Museum of Science Driveway']),\n",
      " 'Elm': set(['Elm']),\n",
      " 'Floor': set(['Boylston Street, 5th Floor']),\n",
      " 'Hall': set(['Faneuil Hall']),\n",
      " 'Hampshire': set(['Hampshire']),\n",
      " 'Highway': set([\"Monsignor O'Brien Highway\", 'Santilli Highway']),\n",
      " 'Holland': set(['Holland']),\n",
      " 'Hwy': set([\"Monsignor O'Brien Hwy\"]),\n",
      " 'LEVEL': set(['LOMASNEY WAY, ROOF LEVEL']),\n",
      " 'Lafayette': set(['Avenue De Lafayette']),\n",
      " 'Mall': set(['Cummington Mall']),\n",
      " 'Market': set(['Faneuil Hall Market']),\n",
      " 'Newbury': set(['Newbury']),\n",
      " 'Park': set(['Acorn Park',\n",
      "              'Austin Park',\n",
      "              'Canal Park',\n",
      "              'Exeter Park',\n",
      "              'Giles Park',\n",
      "              'Granton Park']),\n",
      " 'Pkwy': set(['Birmingham Pkwy']),\n",
      " 'Pl': set(['Longfellow Pl']),\n",
      " 'Plaza': set(['Two Center Plaza']),\n",
      " 'Rd': set(['Abby Rd', 'Aberdeen Rd', 'Bristol Rd', 'Soldiers Field Rd']),\n",
      " 'Row': set(['Assembly Row', 'Professors Row']),\n",
      " 'ST': set(['Newton ST']),\n",
      " 'Sq.': set(['1 Kendall Sq.']),\n",
      " 'St': set(['1629 Cambridge St',\n",
      "            'Antwerp St',\n",
      "            'Arsenal St',\n",
      "            'Athol St',\n",
      "            'Bagnal St',\n",
      "            'Brentwood St',\n",
      "            'Cambridge St',\n",
      "            'Charles St',\n",
      "            'Cummington St',\n",
      "            'Dane St',\n",
      "            'Duval St',\n",
      "            'Elm St',\n",
      "            'Everett St',\n",
      "            'Hampshire St',\n",
      "            'Holton St',\n",
      "            'Kirkland St',\n",
      "            'Leighton St',\n",
      "            'Litchfield St',\n",
      "            'Lothrop St',\n",
      "            'Mackin St',\n",
      "            'Main St',\n",
      "            'Merrill St',\n",
      "            'Mt Auburn St',\n",
      "            'N Beacon St',\n",
      "            'Norfolk St',\n",
      "            'Portsmouth St',\n",
      "            'Richardson St',\n",
      "            'South Waverly St',\n",
      "            'Ware St',\n",
      "            'Waverly St',\n",
      "            'Winter St']),\n",
      " 'St,': set(['Walnut St,']),\n",
      " 'St.': set(['Albion St.',\n",
      "             'Banks St.',\n",
      "             'Boylston St.',\n",
      "             'Elm St.',\n",
      "             'Main St.',\n",
      "             'Marshall St.',\n",
      "             'Pearl St.',\n",
      "             'Prospect St.',\n",
      "             \"Saint Mary's St.\",\n",
      "             'Stuart St.']),\n",
      " 'Terrace': set(['Alberta Terrace', 'Norfolk Terrace']),\n",
      " 'Way': set(['Artisan Way',\n",
      "             'Cedar Lane Way',\n",
      "             'David G Mugar Way',\n",
      "             'Harry Agganis Way',\n",
      "             'Memorial Way',\n",
      "             'Yawkey Way']),\n",
      " 'Windsor': set(['Windsor']),\n",
      " 'Winsor': set(['Winsor']),\n",
      " 'floor': set(['First Street, 18th floor', 'Sidney Street, 2nd floor']),\n",
      " 'place': set(['argus place']),\n",
      " 'st': set(['Main st'])}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Heights\", \"North\", \"East\", \"West\", \"South\"]\n",
    "\n",
    "\n",
    "filename = 'boston.osm'\n",
    "                \n",
    "def process_addressanomalies(addressvalue): \n",
    "    match = street_type_re.search(addressvalue)\n",
    "    if match: \n",
    "        street_type = match.group()\n",
    "        if street_type not in expected: \n",
    "            street_types[street_type].add(addressvalue)\n",
    "        \n",
    "def read_file():\n",
    "    for _, element in ET.iterparse(filename): \n",
    "        if element.tag == 'tag': \n",
    "            key=element.get('k')\n",
    "            if 'addr:street' in key:\n",
    "                addr_value = element.get('v')\n",
    "                process_addressanomalies(addr_value)\n",
    "    return street_types                \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    street_types = defaultdict(set)\n",
    "    read_key = read_file()\n",
    "#     print read_key\n",
    "pprint.pprint(dict(read_key))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On quick review of the output from the previous step we see that \n",
    "1. Street has different variations. E.g. Some forms include \"st\", \"St\", \"St.\" , \"St,\" and also \"ST\" \n",
    "2. Similarly we also see that Avenue is sometimes referred to as \"Ave\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Cleansing\n",
    "\n",
    "This step involves creation of logic to cleanse the anomalies identified in the previous step. This steps involves a mapping dictionary which has the mapping between the incorrect format and the correct format of the street names in the form of key/value pairs. The psuedocode involves utilizing some of old code, that involved building a dictionary, by grouping street names that ended with a similar value. \n",
    "\n",
    "The cleansing step involves looping through the dictionary of elements and validating to see if the value can be found in the mapping dictionary. If the mapping is found then appropriate replacement is done to the street name using the python replace method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walnut St, ==> Walnut Street\n",
      "Pearl St. ==> Pearl Street\n",
      "Banks St. ==> Banks Street\n",
      "Marshall St. ==> Marshall Street\n",
      "Prospect St. ==> Prospect Street\n",
      "Main St. ==> Main Street\n",
      "Albion St. ==> Albion Street\n",
      "Saint Mary's St. ==> Saint Mary's Street\n",
      "Boylston St. ==> Boylston Street\n",
      "Stuart St. ==> Stuart Street\n",
      "Elm St. ==> Elm Street\n",
      "Newton ST ==> Newton Street\n",
      "Brighton Ave. ==> Brighton Avenue\n",
      "Spaulding Ave. ==> Spaulding Avenue\n",
      "Massachusetts Ave. ==> Massachusetts Avenue\n",
      "Somerville Ave. ==> Somerville Avenue\n",
      "Brentwood St ==> Brentwood Street\n",
      "Athol St ==> Athol Street\n",
      "Everett St ==> Everett Street\n",
      "South Waverly St ==> South Waverly Street\n",
      "Litchfield St ==> Litchfield Street\n",
      "Hampshire St ==> Hampshire Street\n",
      "Main St ==> Main Street\n",
      "Cambridge St ==> Cambridge Street\n",
      "Arsenal St ==> Arsenal Street\n",
      "Merrill St ==> Merrill Street\n",
      "Antwerp St ==> Antwerp Street\n",
      "1629 Cambridge St ==> 1629 Cambridge Street\n",
      "Elm St ==> Elm Street\n",
      "Lothrop St ==> Lothrop Street\n",
      "Charles St ==> Charles Street\n",
      "Dane St ==> Dane Street\n",
      "Norfolk St ==> Norfolk Street\n",
      "Bagnal St ==> Bagnal Street\n",
      "Cummington St ==> Cummington Street\n",
      "Holton St ==> Holton Street\n",
      "Mackin St ==> Mackin Street\n",
      "Waverly St ==> Waverly Street\n",
      "Mt Auburn St ==> Mt Auburn Street\n",
      "Duval St ==> Duval Street\n",
      "Kirkland St ==> Kirkland Street\n",
      "N Beacon St ==> N Beacon Street\n",
      "Leighton St ==> Leighton Street\n",
      "Richardson St ==> Richardson Street\n",
      "Winter St ==> Winter Street\n",
      "Ware St ==> Ware Street\n",
      "Portsmouth St ==> Portsmouth Street\n",
      "738 Commonwealth Ave ==> 738 Commonwealth Avenue\n",
      "Somerville Ave ==> Somerville Avenue\n",
      "Massachusetts Ave ==> Massachusetts Avenue\n",
      "Commonwealth Ave ==> Commonwealth Avenue\n",
      "Highland Ave ==> Highland Avenue\n",
      "Francesca Ave ==> Francesca Avenue\n",
      "Josephine Ave ==> Josephine Avenue\n",
      "Mystic Ave ==> Mystic Avenue\n",
      "Lexington Ave ==> Lexington Avenue\n",
      "Concord Ave ==> Concord Avenue\n",
      "Western Ave ==> Western Avenue\n",
      "Willow Ave ==> Willow Avenue\n",
      "College Ave ==> College Avenue\n",
      "Morrison Ave ==> Morrison Avenue\n",
      "Boston Ave ==> Boston Avenue\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Heights\", \"North\", \"East\", \"West\", \"South\"]\n",
    "\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Rd.\": \"Road\", \n",
    "            \"Ave\": \"Avenue\", \n",
    "            \"Ave.\": \"Avenue\", \n",
    "            \"St\": \"Street\", \n",
    "            \"St,\": \"Street\", \n",
    "           \"St.\": \"Street\", \n",
    "           \"ST\": \"Street\"\n",
    "            }\n",
    "\n",
    "\n",
    "filename = 'boston.osm'\n",
    "                \n",
    "def process_addressanomalies(addressvalue): \n",
    "    match = street_type_re.search(addressvalue)\n",
    "    if match: \n",
    "        street_type = match.group()\n",
    "        if street_type not in expected: \n",
    "            street_types[street_type].add(addressvalue)\n",
    "\n",
    "def update_name(): \n",
    "    for k, v in read_key.iteritems(): \n",
    "        for vitem in v: \n",
    "            match = street_type_re.search(vitem) \n",
    "            val =  match.group(0)\n",
    "            if val in mapping: \n",
    "                new_name = vitem.replace(match.group(0), mapping[match.group(0)])\n",
    "                print vitem, \"==>\", new_name\n",
    "            \n",
    "\n",
    "def read_file():\n",
    "    for _, element in ET.iterparse(filename): \n",
    "        if element.tag == 'tag': \n",
    "            key=element.get('k')\n",
    "            if 'addr:street' in key:\n",
    "                addr_value = element.get('v')\n",
    "                process_addressanomalies(addr_value)\n",
    "    return street_types                \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    street_types = defaultdict(set)\n",
    "    read_key = read_file()\n",
    "    better_adress = update_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# XML to a JSON Conversion \n",
    "## This step involves parsing through the XML file to create a JSON file, which will then be used to import into mongoDB. We need to follow the below rules for translation \n",
    "\n",
    "* Process only 2 types of top level tags: \"node\" and \"way\"\n",
    "* All attributes of \"node\" and \"way\" should be turned into regular key/value pairs, except: attributes in the CREATED array should be added under a key \"created\", attributes for latitude and longitude should be added to a \"pos\" array, for use in geospacial indexing. Make sure the values inside \"pos\" array are floats and not strings.\n",
    "* If second level tag \"k\" value contains problematic characters, it should be ignored\n",
    "* If second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"\n",
    "* If second level tag \"k\" value does not start with \"addr:\", but contains \":\", you can process it same as any other tag.\n",
    "* If there is a second \":\" that separates the type/direction of a street, the tag should be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "def floatOrNofloat(n):\n",
    "    return float(n) if n else None\n",
    "    \n",
    "def shape_element(element): \n",
    "    node = defaultdict(dict) \n",
    "    if element.tag == \"node\" or element.tag == \"way\":\n",
    "        \n",
    "        node[\"tag\"] = element.tag\n",
    "\n",
    "        node [\"id\"] = element.get('id')\n",
    "\n",
    "        lat = element.get('lat')\n",
    "\n",
    "        lon = element.get('lon')\n",
    "\n",
    "        if lat or lon:\n",
    "            node['pos'] = [floatOrNofloat(lat), floatOrNofloat(lon)]\n",
    "        \n",
    "        node[\"created\"] = {}\n",
    "\n",
    "        for key in CREATED:\n",
    "            node[\"created\"][key] = element.get(key)\n",
    "        \n",
    "        for child in element.getchildren():\n",
    "            \n",
    "            key = child.get(\"k\")\n",
    "            ref = child.get(\"ref\")\n",
    "            \n",
    "            if key == 'address': \n",
    "                node['fulladdress'] = child.get('v')\n",
    "            \n",
    "            if key is not None: \n",
    "                if key.startswith('addr:'):\n",
    "                    split_key = key.split(\":\")\n",
    "                    node['address'][split_key[1]] = child.get('v')\n",
    "                elif 'amenity' in key: \n",
    "                    node['amenity'] = child.get('v')\n",
    "                elif 'name' in key: \n",
    "                    node['name'] = child.get('v')\n",
    "            \n",
    "            if ref: \n",
    "                if \"node_refs\" not in node: \n",
    "                    node[\"node_refs\"] = []\n",
    "                else: \n",
    "                    node[\"node_refs\"].append(ref)\n",
    "        \n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "\n",
    "    \n",
    "def process_map(file_in, pretty = False):\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data\n",
    "\n",
    "def test():\n",
    "    data = process_map('Boston.osm', True)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the step above is the creation of **\"Boston.osm.json\"** file, which is later been used to import into MongoDB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up for Mongo Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), u'boston')\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient()\n",
    "db = client.boston\n",
    "print db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis/Data Exploration in MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing the Size of the Original OSM File and the JSON File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original OSM file is 100.298776 MB\n",
      "The JSON file is 145.946684 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print 'The original OSM file is {} MB'.format(os.path.getsize('Boston.osm')/1.0e6)\n",
    "print 'The JSON file is {} MB'.format(os.path.getsize('Boston.osm' + \".json\")/1.0e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boston = db['bostonc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520261"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.find().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Unique Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "827"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(boston.distinct('created.user'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Nodes and Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 444899\n",
      "Number of ways: 75362\n"
     ]
    }
   ],
   "source": [
    "print \"Number of nodes:\",boston.find({'tag': 'node'}).count()\n",
    "print \"Number of ways:\", boston.find({'tag': 'way'}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10 Contributors along with the UserNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': u'crschmidt', u'count': 269155},\n",
      " {u'_id': u'jremillard-massgis', u'count': 64989},\n",
      " {u'_id': u'wambag', u'count': 29468},\n",
      " {u'_id': u'OceanVortex', u'count': 27793},\n",
      " {u'_id': u'ryebread', u'count': 21755},\n",
      " {u'_id': u'morganwahl', u'count': 20291},\n",
      " {u'_id': u'mapper999', u'count': 8309},\n",
      " {u'_id': u'cspanring', u'count': 6817},\n",
      " {u'_id': u'JasonWoof', u'count': 5439},\n",
      " {u'_id': u'synack', u'count': 5042}]\n"
     ]
    }
   ],
   "source": [
    "result = boston.aggregate( [\n",
    "                                        { \"$group\" : {\"_id\" : \"$created.user\", \"count\" : { \"$sum\" : 1} } },\n",
    "                                        { \"$sort\" : {\"count\" : -1} }, \n",
    "                                        { \"$limit\" : 10 } ] )\n",
    "\n",
    "pprint.pprint(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Top 50 Amenities in the Boston Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': u'parking', u'count': 545},\n",
      " {u'_id': u'bench', u'count': 495},\n",
      " {u'_id': u'restaurant', u'count': 398},\n",
      " {u'_id': u'bicycle_parking', u'count': 214},\n",
      " {u'_id': u'school', u'count': 205},\n",
      " {u'_id': u'place_of_worship', u'count': 184},\n",
      " {u'_id': u'library', u'count': 162},\n",
      " {u'_id': u'cafe', u'count': 158},\n",
      " {u'_id': u'fast_food', u'count': 114},\n",
      " {u'_id': u'bicycle_rental', u'count': 89},\n",
      " {u'_id': u'university', u'count': 77},\n",
      " {u'_id': u'post_box', u'count': 69},\n",
      " {u'_id': u'bank', u'count': 65},\n",
      " {u'_id': u'waste_basket', u'count': 59},\n",
      " {u'_id': u'pub', u'count': 49},\n",
      " {u'_id': u'fuel', u'count': 41},\n",
      " {u'_id': u'fountain', u'count': 34},\n",
      " {u'_id': u'pharmacy', u'count': 34},\n",
      " {u'_id': u'atm', u'count': 33},\n",
      " {u'_id': u'hospital', u'count': 31},\n",
      " {u'_id': u'fire_station', u'count': 31},\n",
      " {u'_id': u'drinking_water', u'count': 31},\n",
      " {u'_id': u'car_sharing', u'count': 28},\n",
      " {u'_id': u'bar', u'count': 28},\n",
      " {u'_id': u'parking_space', u'count': 27},\n",
      " {u'_id': u'post_office', u'count': 24},\n",
      " {u'_id': u'theatre', u'count': 23},\n",
      " {u'_id': u'college', u'count': 22},\n",
      " {u'_id': u'bicycle_repair_station', u'count': 21},\n",
      " {u'_id': u'recycling', u'count': 16},\n",
      " {u'_id': u'police', u'count': 15},\n",
      " {u'_id': u'toilets', u'count': 14},\n",
      " {u'_id': u'telephone', u'count': 12},\n",
      " {u'_id': u'emergency_phone', u'count': 10},\n",
      " {u'_id': u'public_building', u'count': 9},\n",
      " {u'_id': u'dentist', u'count': 8},\n",
      " {u'_id': u'arts_centre', u'count': 8},\n",
      " {u'_id': u'parking_entrance', u'count': 7},\n",
      " {u'_id': u'cinema', u'count': 7},\n",
      " {u'_id': u'grave_yard', u'count': 7},\n",
      " {u'_id': u'townhall', u'count': 6},\n",
      " {u'_id': u'doctors', u'count': 5},\n",
      " {u'_id': u'social_facility', u'count': 5},\n",
      " {u'_id': u'car_rental', u'count': 5},\n",
      " {u'_id': u'marketplace', u'count': 5},\n",
      " {u'_id': u'vending_machine', u'count': 4},\n",
      " {u'_id': u'car_wash', u'count': 4},\n",
      " {u'_id': u'community_centre', u'count': 4},\n",
      " {u'_id': u'swimming_pool', u'count': 3},\n",
      " {u'_id': u'magazine_box', u'count': 3}]\n"
     ]
    }
   ],
   "source": [
    "result = boston.aggregate( [            {'$match': {'amenity': {'$exists': 1}}},\n",
    "                                        { \"$group\" : {\"_id\" : \"$amenity\", \"count\" : { \"$sum\" : 1} } },\n",
    "                                        { \"$sort\" : {\"count\" : -1} }, \n",
    "                                        { \"$limit\" : 50 } ] )\n",
    "\n",
    "pprint.pprint(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extracting the List of Colleges from the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'College': u'North Bennet Street School', u'Name': 1},\n",
      " {u'College': u'Radcliffe Quad', u'Name': 1},\n",
      " {u'College': u'Bunker Hill Community College', u'Name': 1},\n",
      " {u'College': u'Emerson College', u'Name': 7},\n",
      " {u'College': u'Berklee College of Music', u'Name': 7},\n",
      " {u'College': u'Emerson College \\u2013 Walker Building', u'Name': 1},\n",
      " {u'College': u'Emerson College \\u2013 Tuffte Performing Arts Center',\n",
      "  u'Name': 1},\n",
      " {u'College': u'Fisher College', u'Name': 1},\n",
      " {u'College': u'Emerson College - Little Building', u'Name': 1},\n",
      " {u'College': u'Emerson College \\u2013 Piano Row', u'Name': 1}]\n"
     ]
    }
   ],
   "source": [
    "colleges = boston.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1},\n",
    "                                 \"amenity\":\"college\",}},      \n",
    "                      {\"$group\":{\"_id\":{\"Name\":\"$name\"},\n",
    "                                 \"count\":{\"$sum\":1}}},\n",
    "                      {\"$project\":{\"_id\":0,\n",
    "                                  \"College\":\"$_id.Name\",\n",
    "                                  \"Name\":\"$count\"}},\n",
    "                      {\"$sort\":{\"Count\":-1}}, \n",
    "                      {\"$limit\":10}])\n",
    "pprint.pprint(list(colleges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This list is definitely missing some of the key universities in the Boston Area like Harvard, MIT, NorthEastern. On further review of the dataset I noticed that the missing schools and colleges are infact a part of the dataset, they just don't have an amenity of college attached to them** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the list of Public Buildings in the Boston Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'Building': None, u'Name': 1},\n",
      " {u'Building': u'Social Security Administration', u'Name': 1},\n",
      " {u'Building': u'Suffolk', u'Name': 5},\n",
      " {u'Building': u'Middlesex', u'Name': 2}]\n"
     ]
    }
   ],
   "source": [
    "building = boston.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1},\n",
    "                                 \"amenity\":\"public_building\",}},      \n",
    "                      {\"$group\":{\"_id\":{\"Name\":\"$name\"},\n",
    "                                 \"count\":{\"$sum\":1}}},\n",
    "                      {\"$project\":{\"_id\":0,\n",
    "                                  \"Building\":\"$_id.Name\",\n",
    "                                  \"Name\":\"$count\"}},\n",
    "                      {\"$sort\":{\"Count\":-1}}, \n",
    "                      {\"$limit\":10}])\n",
    "pprint.pprint(list(building))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the Top Cities in the Boston Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': u'Boston', u'count': 619},\n",
      " {u'_id': u'Cambridge', u'count': 555},\n",
      " {u'_id': u'Somerville', u'count': 240},\n",
      " {u'_id': u'Arlington', u'count': 172},\n",
      " {u'_id': u'Allston', u'count': 17},\n",
      " {u'_id': u'Arlington, MA', u'count': 9},\n",
      " {u'_id': u'Charlestown', u'count': 9},\n",
      " {u'_id': u'Watertown', u'count': 9},\n",
      " {u'_id': u'Cambridge, MA', u'count': 8},\n",
      " {u'_id': u'Brookline', u'count': 7}]\n"
     ]
    }
   ],
   "source": [
    "cities = boston.aggregate([\n",
    "        {\"$match\": {\"address.city\":{\"$exists\":1}}}, \n",
    "        {\"$group\":{\"_id\":\"$address.city\", \"count\":{\"$sum\":1}}},\n",
    "        {\"$sort\": {\"count\": -1}}, \n",
    "        {\"$limit\":10}                                 \n",
    "    ])\n",
    "\n",
    "pprint.pprint(list(cities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Other Suggested Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the size of the Boston Data Set that was analyzed and the number of issues that existed with the dataset, it was a lot better than I anticipated. That said, there are definitely areas for improvement. E.g.We noticed inconsistencies with the street names while executing our auditing in Python. In addition we found other issues around missing data, or the data being associated with different types \n",
    "1. When we executed a query to extract the list of colleges in the Boston Area based on amenity == \"college\", the result set was missing some of the key institutions in the Boston area (e.g. MIT, Harvard, NorthEastern). On further analysis by looking at OSM file we noticed that the data is infact present, but just that it was associated with a different type. \n",
    "2. Similarly, when we executed a query to extract the list of public buildings in the Boston Area based on amenity == \"public_building, not a whole lot of buildings showed up. \n",
    "\n",
    "If we further analyze the root cause for 1 and 2, we can definitely conclude that these are the effects of manual contribution from hundreds and hundreds of users over the web. One approach to rectify this would be to use a structured input form, this would force the users to adhere to a standard structure/format; this will definitely reduce the amount of anomalies.\n",
    "\n",
    "We could also do further analysis on other data elements. Some examples are \n",
    "\n",
    "1. Analyzing the post codes to see if the Zipcodes belong to the Boston Area, or whether the Zipcodes have any alphabetical characters in them.\n",
    "2. We could probably do a regular sync of the user entered data in Open Street Maps with some other mapping software like Google MAPS via Google API and clean up some of the data format to be consistent. \n",
    "\n",
    "Note: I am not recommending filling up the missing data, all I am recommending is cleaning up/updating the already entered data with more cleaner version of the data (if available) via the Google API \n",
    "\n",
    "Finally, we could also run competitions (or coding meetups), where we could assign certain datasets to groups of people and have them do a comprehensive analysis and update Open StreetMaps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listed Below are some of the references I used \n",
    "* http://wiki.openstreetmap.org/wiki/Browsing\n",
    "* Udacity Lectures \n",
    "* A lot of StackOverflow Threads (everytime I ran into an error in Python and Regular Expressions)\n",
    "* https://docs.python.org/2/library/re.html\n",
    "* https://regexone.com/references/python\n",
    "* https://pymotw.com/2/xml/etree/ElementTree/parse.html#parsing-an-entire-document\n",
    "* http://effbot.org/zone/element-iterparse.htm\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
